{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-09T17:29:07.748996Z","iopub.execute_input":"2025-05-09T17:29:07.749538Z","iopub.status.idle":"2025-05-09T17:29:08.100651Z","shell.execute_reply.started":"2025-05-09T17:29:07.749469Z","shell.execute_reply":"2025-05-09T17:29:08.099914Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install -q requests torch bitsandbytes transformers sentencepiece accelerate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T17:29:08.101670Z","iopub.execute_input":"2025-05-09T17:29:08.101943Z","iopub.status.idle":"2025-05-09T17:30:23.025663Z","shell.execute_reply.started":"2025-05-09T17:29:08.101917Z","shell.execute_reply":"2025-05-09T17:30:23.024767Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install --upgrade \\\n    pylibraft-cu12==24.12.0 \\\n    rmm-cu12==24.12.0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T17:30:23.026851Z","iopub.execute_input":"2025-05-09T17:30:23.027182Z","iopub.status.idle":"2025-05-09T17:30:37.160764Z","shell.execute_reply.started":"2025-05-09T17:30:23.027145Z","shell.execute_reply":"2025-05-09T17:30:37.160091Z"}},"outputs":[{"name":"stdout","text":"Collecting pylibraft-cu12==24.12.0\n  Downloading pylibraft_cu12-24.12.0.tar.gz (5.6 kB)\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nCollecting rmm-cu12==24.12.0\n  Downloading rmm_cu12-24.12.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m30.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting cuda-python<13.0a0,<=12.6.0,>=12.0 (from pylibraft-cu12==24.12.0)\n  Downloading cuda_python-12.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nRequirement already satisfied: numpy<3.0a0,>=1.23 in /usr/local/lib/python3.11/dist-packages (from pylibraft-cu12==24.12.0) (1.26.4)\nRequirement already satisfied: nvidia-cublas-cu12 in /usr/local/lib/python3.11/dist-packages (from pylibraft-cu12==24.12.0) (12.4.5.8)\nRequirement already satisfied: nvidia-curand-cu12 in /usr/local/lib/python3.11/dist-packages (from pylibraft-cu12==24.12.0) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12 in /usr/local/lib/python3.11/dist-packages (from pylibraft-cu12==24.12.0) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12 in /usr/local/lib/python3.11/dist-packages (from pylibraft-cu12==24.12.0) (12.3.1.170)\nRequirement already satisfied: numba>=0.57 in /usr/local/lib/python3.11/dist-packages (from rmm-cu12==24.12.0) (0.60.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.57->rmm-cu12==24.12.0) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0a0,>=1.23->pylibraft-cu12==24.12.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0a0,>=1.23->pylibraft-cu12==24.12.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0a0,>=1.23->pylibraft-cu12==24.12.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0a0,>=1.23->pylibraft-cu12==24.12.0) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0a0,>=1.23->pylibraft-cu12==24.12.0) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0a0,>=1.23->pylibraft-cu12==24.12.0) (2.4.1)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12->pylibraft-cu12==24.12.0) (12.4.127)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0a0,>=1.23->pylibraft-cu12==24.12.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0a0,>=1.23->pylibraft-cu12==24.12.0) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0a0,>=1.23->pylibraft-cu12==24.12.0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0a0,>=1.23->pylibraft-cu12==24.12.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0a0,>=1.23->pylibraft-cu12==24.12.0) (2024.2.0)\nDownloading rmm_cu12-24.12.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading cuda_python-12.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.0/25.0 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pylibraft-cu12\n  Building wheel for pylibraft-cu12 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for pylibraft-cu12: filename=pylibraft_cu12-24.12.0-cp311-cp311-manylinux_2_28_x86_64.whl size=11802800 sha256=47d3915fd3cdf4022acbd0315f88b12155399ef0b0e77fcac050c459ab6b31b0\n  Stored in directory: /root/.cache/pip/wheels/2a/67/73/9252ad4b3876078a9bca569565977dd588cb54f66bd3bf2e0d\nSuccessfully built pylibraft-cu12\nInstalling collected packages: cuda-python, rmm-cu12, pylibraft-cu12\n  Attempting uninstall: cuda-python\n    Found existing installation: cuda-python 12.8.0\n    Uninstalling cuda-python-12.8.0:\n      Successfully uninstalled cuda-python-12.8.0\n  Attempting uninstall: rmm-cu12\n    Found existing installation: rmm-cu12 25.2.0\n    Uninstalling rmm-cu12-25.2.0:\n      Successfully uninstalled rmm-cu12-25.2.0\n  Attempting uninstall: pylibraft-cu12\n    Found existing installation: pylibraft-cu12 25.2.0\n    Uninstalling pylibraft-cu12-25.2.0:\n      Successfully uninstalled pylibraft-cu12-25.2.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nraft-dask-cu12 25.2.0 requires pylibraft-cu12==25.2.*, but you have pylibraft-cu12 24.12.0 which is incompatible.\ncuml-cu12 25.2.1 requires cuda-python<13.0a0,>=12.6.2, but you have cuda-python 12.6.0 which is incompatible.\ncuml-cu12 25.2.1 requires pylibraft-cu12==25.2.*, but you have pylibraft-cu12 24.12.0 which is incompatible.\ncuml-cu12 25.2.1 requires rmm-cu12==25.2.*, but you have rmm-cu12 24.12.0 which is incompatible.\npylibcudf-cu12 25.2.2 requires cuda-python<13.0a0,>=12.6.2, but you have cuda-python 12.6.0 which is incompatible.\npylibcudf-cu12 25.2.2 requires rmm-cu12==25.2.*, but you have rmm-cu12 24.12.0 which is incompatible.\ncudf-cu12 25.2.2 requires cuda-python<13.0a0,>=12.6.2, but you have cuda-python 12.6.0 which is incompatible.\ncudf-cu12 25.2.2 requires rmm-cu12==25.2.*, but you have rmm-cu12 24.12.0 which is incompatible.\ncuvs-cu12 25.2.1 requires cuda-python<13.0a0,>=12.6.2, but you have cuda-python 12.6.0 which is incompatible.\ncuvs-cu12 25.2.1 requires pylibraft-cu12==25.2.*, but you have pylibraft-cu12 24.12.0 which is incompatible.\nucxx-cu12 0.42.0 requires rmm-cu12==25.2.*, but you have rmm-cu12 24.12.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed cuda-python-12.6.0 pylibraft-cu12-24.12.0 rmm-cu12-24.12.0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from google.colab import userdata\nfrom huggingface_hub import login\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModelForCausalLM\nfrom transformers import TextStreamer\nfrom transformers import BitsAndBytesConfig\nimport torch\nimport gc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T17:32:21.071121Z","iopub.execute_input":"2025-05-09T17:32:21.071775Z","iopub.status.idle":"2025-05-09T17:32:21.075744Z","shell.execute_reply.started":"2025-05-09T17:32:21.071753Z","shell.execute_reply":"2025-05-09T17:32:21.075004Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nfrom huggingface_hub import login\n\nhf_token = UserSecretsClient().get_secret(\"HF_TOKEN\")\nlogin(token=hf_token)   # caches credentials for huggingface-hub\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T17:32:21.261911Z","iopub.execute_input":"2025-05-09T17:32:21.262410Z","iopub.status.idle":"2025-05-09T17:32:21.411322Z","shell.execute_reply.started":"2025-05-09T17:32:21.262385Z","shell.execute_reply":"2025-05-09T17:32:21.410613Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"quant_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=torch.bfloat16,\n    bnb_4bit_quant_type=\"nf4\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T17:32:21.412105Z","iopub.execute_input":"2025-05-09T17:32:21.412286Z","iopub.status.idle":"2025-05-09T17:32:21.416803Z","shell.execute_reply.started":"2025-05-09T17:32:21.412271Z","shell.execute_reply":"2025-05-09T17:32:21.416230Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"LLAMA = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T17:32:21.417420Z","iopub.execute_input":"2025-05-09T17:32:21.417613Z","iopub.status.idle":"2025-05-09T17:32:21.427891Z","shell.execute_reply.started":"2025-05-09T17:32:21.417593Z","shell.execute_reply":"2025-05-09T17:32:21.427280Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"messages = [\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n    {\"role\": \"user\", \"content\": \"Tell a light-hearted joke for a room of ship captains\"}\n  ]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T17:32:21.428571Z","iopub.execute_input":"2025-05-09T17:32:21.429210Z","iopub.status.idle":"2025-05-09T17:32:21.441740Z","shell.execute_reply.started":"2025-05-09T17:32:21.429073Z","shell.execute_reply":"2025-05-09T17:32:21.441224Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Tokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(LLAMA)\ntokenizer.pad_token = tokenizer.eos_token\ninputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(\"cuda\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T17:32:28.604921Z","iopub.execute_input":"2025-05-09T17:32:28.605589Z","iopub.status.idle":"2025-05-09T17:32:29.225463Z","shell.execute_reply.started":"2025-05-09T17:32:28.605563Z","shell.execute_reply":"2025-05-09T17:32:29.224908Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# The model\n\nmodel = AutoModelForCausalLM.from_pretrained(LLAMA, device_map=\"auto\", quantization_config=quant_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T17:32:39.454919Z","iopub.execute_input":"2025-05-09T17:32:39.455602Z","iopub.status.idle":"2025-05-09T17:33:09.308591Z","shell.execute_reply.started":"2025-05-09T17:32:39.455579Z","shell.execute_reply":"2025-05-09T17:33:09.307081Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef01e55bdf244e35b8275919800d09e7"}},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T17:34:39.789271Z","iopub.execute_input":"2025-05-09T17:34:39.790035Z","iopub.status.idle":"2025-05-09T17:34:39.796693Z","shell.execute_reply.started":"2025-05-09T17:34:39.790009Z","shell.execute_reply":"2025-05-09T17:34:39.796157Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128256, 4096)\n    (layers): ModuleList(\n      (0-31): 32 x LlamaDecoderLayer(\n        (self_attn): LlamaAttention(\n          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n)"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"model.push_to_hub(\"premkumarkora/prem-3.1-8B-Instruct\")\ntokenizer.push_to_hub(\"premkumarkora/prem-3.1-8B-Instruct\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T17:36:34.029611Z","iopub.execute_input":"2025-05-09T17:36:34.030241Z","iopub.status.idle":"2025-05-09T17:38:50.215039Z","shell.execute_reply.started":"2025-05-09T17:36:34.030215Z","shell.execute_reply":"2025-05-09T17:38:50.214399Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/1.05G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b78ba2ea5a54ad58a06d31abe6dedaf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1dd5b92e2904a8c81ac3b84142fcec4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.65G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f927351994384e60909a1c67e5ab6b54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"886948d617a249b9bff0cbc9e9ee92c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7fc6fbb1c0f47d4b3e4b05937d9dad3"}},"metadata":{}},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/premkumarkora/prem-3.1-8B-Instruct/commit/973786cde24f3152083afe3b62c899bca54a4ae5', commit_message='Upload tokenizer', commit_description='', oid='973786cde24f3152083afe3b62c899bca54a4ae5', pr_url=None, repo_url=RepoUrl('https://huggingface.co/premkumarkora/prem-3.1-8B-Instruct', endpoint='https://huggingface.co', repo_type='model', repo_id='premkumarkora/prem-3.1-8B-Instruct'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":20},{"cell_type":"markdown","source":"Below is the code to Authenticate the GIT HUB","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nimport os, subprocess\n\n# 1. Retrieve your token\ntoken = UserSecretsClient().get_secret(\"GITHUB_TOKEN\")\nos.environ[\"GITHUB_TOKEN\"] = token\n\n# 2. Configure git\nsubprocess.run([\"git\", \"config\", \"--global\", \"user.name\", \"Your Name\"])\nsubprocess.run([\"git\", \"config\", \"--global\", \"user.email\", \"you@example.com\"])\n# Use the store helper so git will read from ~/.git-credentials\nsubprocess.run([\"git\", \"config\", \"--global\", \"credential.helper\", \"store\"])\n# Write the credential file so git can authenticate non-interactively\ncred = f\"https://{token}:x-oauth-basic@github.com\\n\"\nwith open(os.path.expanduser(\"~/.git-credentials\"), \"w\") as f:\n    f.write(cred)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T17:54:23.124784Z","iopub.execute_input":"2025-05-09T17:54:23.125589Z","iopub.status.idle":"2025-05-09T17:54:23.331285Z","shell.execute_reply.started":"2025-05-09T17:54:23.125561Z","shell.execute_reply":"2025-05-09T17:54:23.330614Z"}},"outputs":[],"execution_count":21}]}